# MirokaÃ¯ DOA Research Robotics

A state-of-the-art Direction of Arrival (DOA) estimation system for robotics applications using deep learning models with multichannel audio processing.

## âš ï¸ Project Status

**This project is currently in progress.** Only DOA basics have been tested and validated. The system is under active development.

## Overview

This project implements deep learning models for estimating the direction of arrival of speech signals using a 4-channel microphone array. The system processes multichannel audio signals and predicts the azimuth angle of sound sources in real-time.

### Key Features

- **State-of-the-art DOA models**: SCATTiny, FiLMMixerSRP, and ReTiNDoA architectures
- **SRP-PHAT baseline**: Steered Response Power with Phase Transform for comparison
- **Real-time processing**: Optimized for low-latency inference
- **Feature extraction**: Multichannel STFT and advanced feature computation
- **VAD integration**: Voice Activity Detection for improved accuracy
- **Flexible training**: Support for on-the-fly data generation and precomputed features

## Architecture

The project supports three main model architectures:

1. **SCATTiny**: SRP-conditioned additive cross-transformer with attention mechanisms
2. **FiLMMixerSRP**: Time-only Mixer with SRP Feature-wise Linear Modulation (FiLM) conditioning
3. **ReTiNDoA**: Retentive cell-based architecture for temporal modeling

All models use a common backbone that pools channel-frequency features and applies MLP layers to produce per-time embeddings.

## Prerequisites

- Python 3.8+
- PyTorch
- NumPy, SciPy
- See `requirements.txt` for full dependencies

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd doa-research-robotics
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. **Important**: Generate Room Impulse Responses (RIR) using the separate `rir_generator` project:
   - The RIR generator should be set up and run to create the RIR bank
   - Update the `rir_root` path in your configuration files to point to the generated RIR bank

## Project Structure

```
doa-research-robotics/
â”œâ”€â”€ configs/              # Configuration YAML files
â”‚   â”œâ”€â”€ train.yaml        # Training configuration
â”‚   â”œâ”€â”€ train_full.yaml   # Full training configuration
â”‚   â”œâ”€â”€ synth.yaml        # Synthetic data configuration
â”‚   â”œâ”€â”€ realtime.yaml     # Real-time inference configuration
â”‚   â””â”€â”€ constraint.yaml   # Constraint-based training
â”œâ”€â”€ scripts/              # Shell scripts
â”‚   â”œâ”€â”€ train_synth.sh    # Train on synthetic data
â”‚   â”œâ”€â”€ make_synth.sh     # Generate synthetic mixtures
â”‚   â”œâ”€â”€ gen_pseudolabels.sh  # Generate pseudo labels
â”‚   â””â”€â”€ rt_demo.sh        # Real-time demonstration
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mirokai_doa/      # Main source code
â”‚       â”œâ”€â”€ train.py      # Training script
â”‚       â”œâ”€â”€ models.py     # Model definitions
â”‚       â”œâ”€â”€ features.py   # Feature extraction
â”‚       â”œâ”€â”€ srp.py        # SRP-PHAT implementation
â”‚       â”œâ”€â”€ losses.py    # Loss functions
â”‚       â”œâ”€â”€ train_utils.py # Training utilities
â”‚       â”œâ”€â”€ mix_batcher.py # Data batching
â”‚       â”œâ”€â”€ precompute_features.py # Feature preprocessing
â”‚       â”œâ”€â”€ realtime.py   # Real-time inference
â”‚       â”œâ”€â”€ vad.py        # Voice Activity Detection
â”‚       â””â”€â”€ models/
â”‚           â””â”€â”€ silero_vad.onnx  # VAD model
â”œâ”€â”€ tests/                # Test files and sample data
â”œâ”€â”€ models/               # Trained model checkpoints (empty initially)
â””â”€â”€ requirements.txt      # Python dependencies
```

## Configuration

The project uses YAML configuration files located in `configs/`. Key configuration sections:

- **dataset**: Paths to RIR bank, speech, noise, and ambiance datasets
- **features**: STFT parameters, sampling rate, azimuth resolution (K bins)
- **microphone**: Array geometry (4-channel Seeed microphone array v2)
- **model**: Architecture-specific hyperparameters

Example configuration structure:
```yaml
dataset:
  rir_root: "/path/to/rir_generator/rir_bank"
  speech_root: "/path/to/LibriSpeech"
  noise_root: "/path/to/noise"
  batch_size: 4

features:
  sr: 16000
  win_s: 0.032
  hop_s: 0.010
  K: 72  # 5Â° resolution (360/72)

microphone:
  positions:
    - [0.0277, 0.0]    # Mic 0: 0Â°
    - [0.0, 0.0277]    # Mic 1: 90Â°
    - [-0.0277, 0.0]   # Mic 2: 180Â°
    - [0.0, -0.0277]   # Mic 3: 270Â°
```

## Usage

### Training

Train a model using one of the available architectures:

```bash
python src/mirokai_doa/train.py \
    --model scat \
    --cfg configs/train.yaml \
    --save-root models
```

Available models: `scat`, `film`, `retin`

### Feature Precomputation

Precompute features for faster training:

```bash
python src/mirokai_doa/precompute_features.py \
    --cfg configs/train.yaml \
    --output-dir features_v1
```

### Real-time Inference

Run real-time DOA estimation:

```bash
python src/mirokai_doa/realtime.py \
    --cfg configs/realtime.yaml \
    --checkpoint models/scat/checkpoint.pth
```

### Using Shell Scripts

```bash
# Train on synthetic data
./scripts/train_synth.sh

# Generate synthetic mixtures
./scripts/make_synth.sh

# Real-time demo
./scripts/rt_demo.sh
```

## RIR Generation

**Important**: Room Impulse Responses (RIR) must be generated using the separate `rir_generator` project before training:

1. Set up and run the `rir_generator` project
2. Generate the RIR bank with appropriate room configurations
3. Update the `rir_root` path in your configuration files
4. Ensure the RIR bank structure matches the expected format

The RIR generator project should be pushed/available separately and is required for proper dataset generation.

## Testing

Run tests to verify feature extraction and SRP functionality:

```bash
# Test feature extraction
python -m pytest tests/test_features.py

# Test SRP-PHAT
python -m pytest tests/test_srp.py
```

## Model Details

### SCATTiny
- SRP-conditioned cross-attention mechanism
- Pooled channel-frequency features with MLP backbone
- Additive cross-attention between SRP prototypes and feature tokens

### FiLMMixerSRP
- Feature-wise Linear Modulation (FiLM) from SRP features
- Temporal 1D mixer blocks with residual connections
- Per-time classification head

### ReTiNDoA
- Retentive cell-based temporal modeling
- Unrolled over time for efficient inference
- Optional delta angle regression

## Development Status

- âœ… DOA basics implemented and tested
- âœ… Model architectures defined
- âœ… Training pipeline functional
- âœ… Feature extraction working
- âš ï¸ RIR generation requires external `rir_generator` project
- ğŸš§ Advanced features in development
- ğŸš§ Full evaluation pipeline pending

## Contributing

This is a research project in active development. Contributions and feedback are welcome.

## License


## Citation

If you use this code in your research, please cite:

```bibtex
@software{mirokai_doa,
  title = {MirokaÃ¯ DOA Research Robotics},
  author = {[Your Name]},
  year = {2025},
  url = {[Repository URL]}
}
```

## Acknowledgments

- Seeed Studio for microphone array hardware specifications
- Silero VAD for voice activity detection
- LibriSpeech for speech datasets
